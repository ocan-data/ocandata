{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inventory\n",
    "> API details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from functools import lru_cache\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from bs4 import BeautifulSoup\n",
    "from .text import get_language\n",
    "from .core import get\n",
    "from typing import List\n",
    "from .text import Bm25Index\n",
    "from .core import parallel\n",
    "import re\n",
    "import os\n",
    "\n",
    "_INVENTORY_URL = 'https://open.canada.ca/data/dataset/4ed351cf-95d8-4c10-97ac-6b3511f359b7/resource/d0df95a8-31a9-46c9-853b-6952819ec7b4/download/inventory.csv'\n",
    "\n",
    "_DATA_DIR = os.path.join(os.path.dirname(__file__), 'data')\n",
    "_EXPIRED_DATASETS = os.path.join(_DATA_DIR, 'ExpiredDatasets.txt')\n",
    "\n",
    "\n",
    "class Inventory:\n",
    "    \"\"\"\n",
    "    The Open Canada Data Inventory\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame = None, language: str = 'en', sort_by_date=True):\n",
    "        self.language = language\n",
    "        if data is None:\n",
    "            data = self.read_inventory(drop_expired=True)\n",
    "        data = data.dropna(subset=['released'])\n",
    "        data = data[data.released.str.match('20[0-9]{2}')]\n",
    "        if 'portal_url_en' in data.columns:\n",
    "            data = data.dropna(subset=['portal_url_en'])\n",
    "            data = data[data['portal_url_en'].str.match('http://')]\n",
    "        self.data = data\n",
    "        if sort_by_date:\n",
    "            self.data = self.data.sort_values(['released'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        self.english_cols = [col for col in data.columns if not col.endswith(\"_fr\")]\n",
    "        self.french_cols = [col for col in data.columns if not col.endswith(\"_en\")]\n",
    "        self.sort_by_date = sort_by_date\n",
    "\n",
    "    def create_search_indexes(self):\n",
    "        \"\"\"\n",
    "        Create the search indexes for the inventory\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Creating search indexes\")\n",
    "        description_col = 'description' if 'description' in self.data.columns else f'description_{self.language}'\n",
    "        self.search_indexes = {'description': Bm25Index(self.data[description_col])}\n",
    "\n",
    "    def search(self, search_term: str):\n",
    "        if not hasattr(self, 'search_indexes'):\n",
    "            self.create_search_indexes()\n",
    "        bm25_index = self.search_indexes['description']\n",
    "        index, scores = bm25_index.get_scores(search_term, 10)\n",
    "        results = self.data.iloc[index].copy().reset_index(drop=True)\n",
    "        return Inventory(results, language=self.language, sort_by_date=False)\n",
    "\n",
    "    @lru_cache(maxsize=2)\n",
    "    def read_inventory(self, drop_expired: bool = True):\n",
    "        \"\"\"\n",
    "        Read the inventory dataset from the Open Canada website\n",
    "        :param drop_expired:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(_INVENTORY_URL) \\\n",
    "            .drop(columns=['ref_number', 'size', 'eligible_for_release', 'user_votes']) \\\n",
    "            .rename(columns={'date_released': 'released', 'date_published': 'published'})\n",
    "        data.portal_url_en = data.portal_url_en.astype(str)\n",
    "        ## Remove expired datasets\n",
    "        if drop_expired:\n",
    "            with open(_EXPIRED_DATASETS, 'r') as f:\n",
    "                expired_datasets = [l.strip() for l in f.readlines()]\n",
    "            data = data[~(data.portal_url_en.isin(expired_datasets) | (data.portal_url_fr.isin(expired_datasets)))]\n",
    "        return data\n",
    "\n",
    "    @property\n",
    "    def en(self):\n",
    "        return self.EN\n",
    "\n",
    "    @property\n",
    "    def EN(self):\n",
    "        cols = [col for col in self.english_cols if not col in ['owner_org', 'owner_org_title']]\n",
    "        view = self.data[cols].rename(columns={col: col.replace(\"_en\", \"\") for col in self.english_cols})\n",
    "        return Inventory(data=view, language='en', sort_by_date=self.sort_by_date)\n",
    "\n",
    "    def _view(self):\n",
    "        if self.language == 'fr':\n",
    "            return self.fr\n",
    "        return self.en\n",
    "\n",
    "    @property\n",
    "    def fr(self):\n",
    "        return self.FR\n",
    "\n",
    "    @property\n",
    "    def FR(self):\n",
    "        cols = [col for col in self.french_cols if not col in ['owner_org', 'owner_org_title']]\n",
    "        view = self.data[cols].rename(columns={col: col.replace(\"_fr\", \"\") for col in self.french_cols})\n",
    "        return Inventory(data=view, language='fr', sort_by_date=self.sort_by_date)\n",
    "\n",
    "    def query(self, query_str):\n",
    "        \"\"\"\n",
    "        Query the data in this inventory object by passing the query down to the dataframe query method\n",
    "        :param query_str: A dataframe query string\n",
    "        :return: A new Inventory instance with the results of the query\n",
    "        \"\"\"\n",
    "        results = self.data.query(query_str)\n",
    "        return Inventory(results)\n",
    "\n",
    "    def _create_dataset(self, record):\n",
    "        if 'title_en' in self.data.columns:\n",
    "            return Dataset(title=record.title_en, description=record.description_en,\n",
    "                           released=record.released, published=record.published,\n",
    "                           publisher=record.publisher_en, url=record.portal_url_en)\n",
    "        elif 'title_fr' in self.data.columns:\n",
    "            return Dataset(title=record.title_fr, description=record.description_fr,\n",
    "                           released=record.released, published=record.published,\n",
    "                           publisher=record.publisher_fr, url=record.portal_url_fr)\n",
    "        else:\n",
    "            return Dataset(title=record.title, description=record.description,\n",
    "                           released=record.released, published=record.published,\n",
    "                           publisher=record.publisher, url=record.portal_url)\n",
    "\n",
    "\n",
    "\n",
    "    def get_active_inactive_datasets(self, inventory_data: pd.DataFrame):\n",
    "        indexes = range(len(inventory_data))\n",
    "        def _get_dataset(index):\n",
    "            obj = inventory_data.iloc[index]\n",
    "            dataset: Dataset = self._create_dataset(obj)\n",
    "            return dataset\n",
    "\n",
    "        datasets = parallel(_get_dataset, indexes)\n",
    "        return [dataset for dataset in datasets if dataset.is_active()], \\\n",
    "               [dataset for dataset in datasets if not dataset.is_active()],\n",
    "\n",
    "    def get_active_dataset_urls(self, inventory_data: pd.DataFrame):\n",
    "        active_datasets, inactive_datasets = self.get_active_inactive_datasets(inventory_data)\n",
    "        return list(set([dataset.url for dataset in active_datasets]))\n",
    "\n",
    "    def get_inactive_dataset_urls(self, inventory_data: pd.DataFrame):\n",
    "        active_datasets, inactive_datasets = self.get_active_inactive_datasets(inventory_data)\n",
    "        return list(set([dataset.url for dataset in inactive_datasets]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        record = self.data.iloc[item]\n",
    "        return self._create_dataset(record)\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_data = self._view()\n",
    "        return repr_data.data.__repr__()\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        repr_obj = self._view()\n",
    "        repr_data = repr_obj.data.drop(columns=['portal_url', 'language', 'program_alignment_architecture'])\n",
    "        html = '<h3>Open Canada Data Inventory</h3>'\n",
    "        html = html + repr_data.to_html(index=False)\n",
    "        return html\n",
    "\n",
    "\n",
    "class DataFrameHolder:\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, item_getter=None, display_columns: List[str] = None):\n",
    "        self.data = data\n",
    "        self.item_getter = item_getter\n",
    "        if display_columns:\n",
    "            self.display_columns = [col for col in data.columns if col in display_columns]\n",
    "        else:\n",
    "            self.display_columns = data.columns\n",
    "        self._set_attributes(data)\n",
    "\n",
    "    def _set_attributes(self, data):\n",
    "        if len(data) == 1:\n",
    "            for column in data:\n",
    "                setattr(self, column, data[column][0])\n",
    "        else:\n",
    "            for column in data:\n",
    "                setattr(self, column, data[column])\n",
    "\n",
    "    @staticmethod\n",
    "    def value_to_dataframe(series_value):\n",
    "        df = series_value.to_frame()\n",
    "        df.columns = ['Value']\n",
    "        df.index.name = 'Column'\n",
    "        return df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if isinstance(item, list):\n",
    "            return self.data[item]\n",
    "        value = self.data.iloc[item]\n",
    "        if self.item_getter:\n",
    "            return self.item_getter(value)\n",
    "        return value\n",
    "\n",
    "    def query(self, query_str: str):\n",
    "        result = self.data.query(query_str)\n",
    "        return DataFrameHolder(result)\n",
    "\n",
    "    def view(self):\n",
    "        return self.data[self.display_columns]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.view().__repr__()\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return self.view()._repr_html_()\n",
    "\n",
    "\n",
    "class Resource(DataFrameHolder):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "\n",
    "    @classmethod\n",
    "    def from_series(cls, series_value):\n",
    "        data = series_value.to_frame().T.reset_index(drop=True)\n",
    "        return cls(data)\n",
    "\n",
    "\n",
    "_DATASET_HTML = \"\"\"\n",
    "<h3>{{title}}</h3>\n",
    "<p>Published on <strong>{{published}}</strong> by <strong>{{publisher}}</strong></p>\n",
    "<h3>Description</h3>\n",
    "<p>{{description}}</p>\n",
    "<h3>Resources</h3>\n",
    "{{resources}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Represents a single Open Canada Dataset\n",
    "    Datasets ontain resources\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, title: str,\n",
    "                 description: str,\n",
    "                 released=None,\n",
    "                 published=None,\n",
    "                 publisher: str = None,\n",
    "                 url: str = None,\n",
    "                 langauge: str = 'en'):\n",
    "        self.title = title\n",
    "        self.description = description\n",
    "        self.released = released\n",
    "        self.published = published\n",
    "        self.publisher = publisher\n",
    "        self.url = url\n",
    "        self.language = get_language(langauge)\n",
    "        resources = load_dataset_resources(self)\n",
    "        self.resources = DataFrameHolder(resources,\n",
    "                                         item_getter=Resource.from_series\n",
    "                                         )\n",
    "\n",
    "    def is_active(self):\n",
    "        \"\"\"\n",
    "        :return: True if this dataset is deleted\n",
    "        \"\"\"\n",
    "        if self.resources is None or len(self.resources) == 0:\n",
    "            return False\n",
    "        if self.resources.data.loc[0, 'Status'] == 'Active':\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def link(self):\n",
    "        return widgets.HTML(f'<a href=\"{self.url}\" target=\"_blank\">{self.title}</a>')\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.resources is None:\n",
    "            return 0\n",
    "        return len(self.resources)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.resources[item]\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        template = Template(_DATASET_HTML)\n",
    "        return template.render(title=self.title,\n",
    "                               description=self.description,\n",
    "                               published=self.published,\n",
    "                               publisher=self.publisher,\n",
    "                               resources='' if self.resources is None else self.resources.data.to_html(index=False,\n",
    "                                                                                                       render_links=True))\n",
    "\n",
    "\n",
    "def get_tables(html):\n",
    "    if html:\n",
    "        soup = BeautifulSoup(html, features='lxml')\n",
    "        tables = []\n",
    "        for table in soup.find_all('table'):\n",
    "            rows = []\n",
    "            for tr in table.find_all('tr'):\n",
    "                row_values = []\n",
    "                cells = tr.find_all('td')\n",
    "                if len(cells) == 0:\n",
    "                    cells = tr.find_all('th')\n",
    "                for td in cells:\n",
    "                    anchor = td.find('a')\n",
    "                    if anchor:\n",
    "                        row_values.append(anchor['href'])\n",
    "                    else:\n",
    "                        row_values.append(td.text.strip())\n",
    "                rows.append(tuple(row_values))\n",
    "                df = pd.DataFrame(rows)\n",
    "                df.columns = df.iloc[0]\n",
    "                df = df.drop(df.index[0]).reset_index(drop=True)\n",
    "                if 'Links' in df.columns:\n",
    "                    df = df.rename(columns={'Links': 'Link'})\n",
    "                df['Status'] = 'Active'\n",
    "            tables.append(df)\n",
    "\n",
    "    return tables\n",
    "\n",
    "\n",
    "def get_deleted_message(soup: BeautifulSoup):\n",
    "    \"\"\"\n",
    "    Looks for text on the page that indicates if the dataset is deleted\n",
    "    :param soup: The BeautifulSoup for the page\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    h1 = soup.find('h1')\n",
    "    if h1:\n",
    "        if h1.text == 'Dataset Deleted' or h1.text == 'Dossier supprimé':\n",
    "            return 'Deleted'\n",
    "    elif soup.title.text == 'Dataset Deleted - Open Government Portal' \\\n",
    "            or soup.title.text == 'Dossier supprimé - Portail du gouvernement ouvert':\n",
    "        return 'Deleted'\n",
    "\n",
    "\n",
    "_RESOURCE_COLUMNS = ['Resource Name', 'Resource Type', 'Format', 'Language', 'Link', 'Status']\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=512)\n",
    "def load_dataset_resources(dataset):\n",
    "    try:\n",
    "        if dataset.url.endswith('csv'):\n",
    "            return pd.DataFrame([(dataset.title, 'Dataset', 'CSV', dataset.language, dataset.url, 'Active')],\n",
    "                                columns=_RESOURCE_COLUMNS)\n",
    "        if dataset.url.endswith('xlsx'):\n",
    "            print('Excel dataset', dataset.url)\n",
    "            return pd.DataFrame([(dataset.title, 'Dataset', 'XLSX', dataset.language, dataset.url, 'Active')],\n",
    "                                columns=_RESOURCE_COLUMNS)\n",
    "        else:\n",
    "            html = get(dataset.url)\n",
    "            resource_table = find_dataset_resource_table(html)\n",
    "            if resource_table is not None:\n",
    "                return resource_table\n",
    "            else:\n",
    "                soup = BeautifulSoup(html, features='lxml')\n",
    "                deleted_message = get_deleted_message(soup)\n",
    "                if deleted_message:\n",
    "                    return pd.DataFrame([(dataset.title, '', '', '', dataset.url, deleted_message)],\n",
    "                                        columns=_RESOURCE_COLUMNS)\n",
    "                else:\n",
    "                    dataset_link = find_dataset_link(soup)\n",
    "                    html = get(dataset_link)\n",
    "                    resource_table = find_dataset_resource_table(html)\n",
    "                    if resource_table is not None:\n",
    "                        return resource_table\n",
    "                    else:\n",
    "                        return pd.DataFrame([(dataset.title, 'Dataset', 'Unknown', dataset.language, dataset.url, 'Error')],\n",
    "                                        columns=_RESOURCE_COLUMNS)\n",
    "    except Exception as e:\n",
    "        # TODO: log error\n",
    "        return pd.DataFrame([(dataset.title, 'Dataset', 'Unknown', dataset.language, dataset.url, 'Error')],\n",
    "                            columns=_RESOURCE_COLUMNS)\n",
    "\n",
    "\n",
    "def find_dataset_resource_table(html: str):\n",
    "    tables = get_tables(html)\n",
    "    if len(tables) > 0:\n",
    "        for table in tables:\n",
    "            if 'Resource Name' in table.columns:\n",
    "                return table\n",
    "\n",
    "\n",
    "def find_resource_urls(html: str):\n",
    "    return None\n",
    "\n",
    "\n",
    "_DATASET_URL = '(http://(open|ouvert)\\.canada\\.ca)?/data/(en|fr)/dataset/(\\w[\\w\\-]{16,})$'\n",
    "dataset_re = re.compile(_DATASET_URL)\n",
    "\n",
    "\n",
    "def get_dataset_links(html_or_soup):\n",
    "    \"\"\"\n",
    "    Find the dataset links on a page\n",
    "    :param html_or_soup: a html string or a BeautifulSoup\n",
    "    :return: a generator with all the links on a page\n",
    "    \"\"\"\n",
    "    if isinstance(html_or_soup, str):\n",
    "        soup = BeautifulSoup(html_or_soup, features='lxml')\n",
    "    else:\n",
    "        soup = html_or_soup\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href', '')\n",
    "        if dataset_re.match(href):\n",
    "            yield href\n",
    "\n",
    "\n",
    "def find_dataset_link(html_or_soup):\n",
    "    \"\"\"\n",
    "    Find a dataset link on a page\n",
    "    :param html_or_soup: a html string or a BeautifulSoup\n",
    "    :return: a single dataset url on a page if there is one\n",
    "    \"\"\"\n",
    "    links = list(get_dataset_links(html_or_soup))\n",
    "    if len(links) > 0:\n",
    "        return links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_inventory.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocandata",
   "language": "python",
   "name": "ocandata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
